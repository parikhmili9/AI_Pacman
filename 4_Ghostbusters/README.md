# Ghostbusters - BNs and HMMs in Pacman

# Introduction
Pacman spends his life running from ghosts, but things were not always so. Legend has it that many years ago, Pacman’s great grandfather Grandpac learned to hunt ghosts for sport. However, he was blinded by his power and could only track ghosts by their banging and clanging.

In this project, I designed Pacman agents that use sensors to locate and eat invisible ghosts. I will advance from locating single, stationary ghosts to hunting packs of multiple moving ghosts with ruthless efficiency.

After downloading the code (tracking.zip), unzipping it, and changing to the directory, you should be able to play a game of Pacman by typing the following at the command line:
```
python pacman.py
```


In the CS 188 version of Ghostbusters, the goal is to hunt down scared but invisible ghosts. Pacman, ever resourceful, is equipped with sonar (ears) that provides noisy readings of the Manhattan distance to each ghost. The game ends when Pacman has eaten all the ghosts. To start, try playing a game yourself using the keyboard.
```
python busters.py
```
The blocks of color indicate where the each ghost could possibly be, given the noisy distance readings provided to Pacman. The noisy distances at the bottom of the display are always non-negative, and always within 7 of the true distance. The probability of a distance reading decreases exponentially with its difference from the true distance.

The primary task in this project is to implement inference to track the ghosts. For the keyboard based game above, a crude form of inference was implemented for you by default: all squares in which a ghost could possibly be are shaded by the color of the ghost. Naturally, we want a better estimate of the ghost’s position. Fortunately, Bayes Nets provide us with powerful tools for making the most of the information we have. Throughout the rest of this project, I will implement algorithms for performing both exact and approximate inference using Bayes Nets.

There are 2 types of tests in this project, as differentiated by their `.test` files found in the subdirectories of the `test_cases` folder. For tests of class `DoubleInferenceAgentTest`, we will see visualizations of the inference distributions generated by the code, but all Pacman actions will be pre-selected according to the actions of the staff implementation. This is necessary to allow comparision of the distributions with the staff’s distributions. The second type of test is `GameScoreTest`, in which the `BustersAgent` will actually select actions for Pacman and we will watch our Pacman play and win games.

It useful to run a single test at a time. In order to do this you we need to use the `-t` flag with the autograder. For example if you only want to run the first test of question 1, use:
```
python autograder.py -t test_cases/q1/1-ObsProb
```
In general, all test cases can be found inside `test_cases/q*`.

For this project, it is possible sometimes for the autograder to time out if running the tests with graphics. To accurately determine whether or not this code is efficient enough, we should run the tests with the `--no-graphics` flag.



# Implementation
Followed all the steps from here: https://inst.eecs.berkeley.edu/~cs188/fa19/project4/

# Autograder (How to evaluate the program):
This project includes an autograder for you to grade your answers on your machine. This can be run with the command:
```
python autograder.py
```

# How to run
Download the folders and install them locally. You can run these commands on the terminal while being in the folder /reinforcement: <br /> <br />
1. Observation Probability:
```
  $ python autograder.py -q q1
```
2. Exact Inference Observation:
```
  $ python autograder.py -q q2
  $ python autograder.py -q q2 --no-graphics
```
3. Exact Inference with Time Elapse:
```
  $ newPosDist = self.getPositionDistribution(gameState, oldPos)
  $ python autograder.py -q q3
  $ python autograder.py -q q3 --no-graphics
```
4. Exact Inference Full Test:
```
  $ successorPosition = Actions.getSuccessor(position, action)
  $ python autograder.py -q q4
  $ python autograder.py -q q4 --no-graphics
```
5. Approximate Inference Initialization and Beliefs:
```
  $ python autograder.py -q q5
```
6. Approximate Inference Observation:
```
  $ python autograder.py -q q6
  $ python autograder.py -q q6 --no-graphics
```
7. Approximate Inference with Time Elapse:
```
  $ newPosDist = self.getPositionDistribution(gameState, oldPos)
  $ python autograder.py -q q7
  $ python autograder.py -q q7 --no-graphics
```
8. Joint Particle Filter Observation:
```
  $ python autograder.py -q q8
  $ python autograder.py -q q8 --no-graphics
```
9. Joint Particle Filter Observation:
```
  $ python autograder.py -q q9
  $ python autograder.py -q q9 --no-graphics
```
10. Joint Particle Filter Time Elapse and Full Test:
```
  $ python autograder.py -q q10
  $ python autograder.py -q q10 --no-graphics
```




